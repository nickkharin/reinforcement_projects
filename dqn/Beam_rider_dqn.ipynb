{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RZq1KcgtrCXL",
        "outputId": "83a94263-ae88-4abc-83a6-1cd261811b30"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: gymnasium[atari] in /usr/local/lib/python3.10/dist-packages (1.0.0)\n",
            "Requirement already satisfied: numpy>=1.21.0 in /usr/local/lib/python3.10/dist-packages (from gymnasium[atari]) (1.26.4)\n",
            "Requirement already satisfied: cloudpickle>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from gymnasium[atari]) (3.1.0)\n",
            "Requirement already satisfied: typing-extensions>=4.3.0 in /usr/local/lib/python3.10/dist-packages (from gymnasium[atari]) (4.12.2)\n",
            "Requirement already satisfied: farama-notifications>=0.0.1 in /usr/local/lib/python3.10/dist-packages (from gymnasium[atari]) (0.0.4)\n",
            "Requirement already satisfied: ale-py>=0.9 in /usr/local/lib/python3.10/dist-packages (from gymnasium[atari]) (0.10.1)\n",
            "Requirement already satisfied: gymnasium[accept-rom-license] in /usr/local/lib/python3.10/dist-packages (1.0.0)\n",
            "\u001b[33mWARNING: gymnasium 1.0.0 does not provide the extra 'accept-rom-license'\u001b[0m\u001b[33m\n",
            "\u001b[0mRequirement already satisfied: numpy>=1.21.0 in /usr/local/lib/python3.10/dist-packages (from gymnasium[accept-rom-license]) (1.26.4)\n",
            "Requirement already satisfied: cloudpickle>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from gymnasium[accept-rom-license]) (3.1.0)\n",
            "Requirement already satisfied: typing-extensions>=4.3.0 in /usr/local/lib/python3.10/dist-packages (from gymnasium[accept-rom-license]) (4.12.2)\n",
            "Requirement already satisfied: farama-notifications>=0.0.1 in /usr/local/lib/python3.10/dist-packages (from gymnasium[accept-rom-license]) (0.0.4)\n"
          ]
        }
      ],
      "source": [
        "!pip install gymnasium[atari]\n",
        "!pip install gymnasium[accept-rom-license]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uNNNNl8UrTgn"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "!apt install python-opengl\n",
        "!apt install xvfb\n",
        "!pip3 install pyvirtualdisplay\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "guysFuaArcOY",
        "outputId": "0a2769bf-1c36-46ca-fa6e-28526093cf3a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: ale-py in /usr/local/lib/python3.10/dist-packages (0.10.1)\n",
            "Requirement already satisfied: numpy>1.20 in /usr/local/lib/python3.10/dist-packages (from ale-py) (1.26.4)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from ale-py) (4.12.2)\n"
          ]
        }
      ],
      "source": [
        "!pip install ale-py"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kk7wRUMOtl-w"
      },
      "outputs": [],
      "source": [
        "import gymnasium as gym\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import numpy as np\n",
        "import random\n",
        "import ale_py\n",
        "import cv2\n",
        "import imageio\n",
        "from collections import deque\n",
        "from IPython.display import HTML\n",
        "from base64 import b64encode\n",
        "\n",
        "# Neural Network for DQN\n",
        "class DQN(nn.Module):\n",
        "    def __init__(self, input_dim, output_dim):\n",
        "        super(DQN, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(4, 32, kernel_size=8, stride=4)\n",
        "        self.conv2 = nn.Conv2d(32, 64, kernel_size=4, stride=2)\n",
        "        self.conv3 = nn.Conv2d(64, 64, kernel_size=3, stride=1)\n",
        "        self.fc1 = nn.Linear(64 * 7 * 7, 512)\n",
        "        self.fc2 = nn.Linear(512, output_dim)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = torch.relu(self.conv1(x))\n",
        "        x = torch.relu(self.conv2(x))\n",
        "        x = torch.relu(self.conv3(x))\n",
        "        x = x.view(x.size(0), -1)\n",
        "        x = torch.relu(self.fc1(x))\n",
        "        return self.fc2(x)\n",
        "\n",
        "# Hyperparameters\n",
        "env_name = \"ALE/BeamRider-v5\"\n",
        "gamma = 0.99\n",
        "learning_rate = 1e-4\n",
        "batch_size = 64\n",
        "epsilon_start = 1.0\n",
        "epsilon_end = 0.01\n",
        "epsilon_decay = 50000\n",
        "memory_size = 50000\n",
        "target_update = 1000\n",
        "num_episodes = 500\n",
        "\n",
        "# Experience Replay Memory\n",
        "class ReplayMemory:\n",
        "    def __init__(self, capacity):\n",
        "        self.memory = deque(maxlen=capacity)\n",
        "\n",
        "    def push(self, state, action, reward, next_state, done):\n",
        "        self.memory.append((state, action, reward, next_state, done))\n",
        "\n",
        "    def sample(self, batch_size):\n",
        "        return random.sample(self.memory, batch_size)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.memory)\n",
        "\n",
        "# Epsilon-greedy policy\n",
        "def epsilon_greedy_policy(state, epsilon, n_actions, policy_net):\n",
        "    if random.random() < epsilon:\n",
        "        return random.randint(0, n_actions - 1)\n",
        "    else:\n",
        "        with torch.no_grad():\n",
        "            state = torch.tensor(np.array(state), dtype=torch.float32).unsqueeze(0)\n",
        "            return policy_net(state).argmax(dim=1).item()\n",
        "\n",
        "# Training loop\n",
        "def train_dqn():\n",
        "    env = gym.make(env_name, render_mode='rgb_array')\n",
        "    n_actions = env.action_space.n\n",
        "\n",
        "    policy_net = DQN((4, 84, 84), n_actions)\n",
        "    target_net = DQN((4, 84, 84), n_actions)\n",
        "    target_net.load_state_dict(policy_net.state_dict())\n",
        "    target_net.eval()\n",
        "\n",
        "    optimizer = optim.Adam(policy_net.parameters(), lr=learning_rate)\n",
        "    memory = ReplayMemory(memory_size)\n",
        "\n",
        "    steps_done = 0\n",
        "    for episode in range(num_episodes):\n",
        "        state, _ = env.reset()\n",
        "        state_buffer = deque(maxlen=4)\n",
        "        state = cv2.cvtColor(state, cv2.COLOR_RGB2GRAY)\n",
        "        state = cv2.resize(state, (84, 84))\n",
        "        state = np.array(state, dtype=np.uint8)  # Resize to 84x84\n",
        "        state_buffer.extend([state] * 4)\n",
        "        total_reward = 0\n",
        "        done = False\n",
        "\n",
        "        step = 0\n",
        "        max_steps = 1000\n",
        "        while not done and step < max_steps:\n",
        "            stacked_state = np.stack(state_buffer, axis=0)\n",
        "            epsilon = epsilon_end + (epsilon_start - epsilon_end) * np.exp(-1. * steps_done / epsilon_decay)\n",
        "            action = epsilon_greedy_policy(stacked_state, epsilon, n_actions, policy_net)\n",
        "            next_state, reward, done, truncated, _ = env.step(action)\n",
        "            next_state = cv2.cvtColor(next_state, cv2.COLOR_RGB2GRAY)\n",
        "            next_state = cv2.resize(next_state, (84, 84))\n",
        "            next_state = np.array(next_state, dtype=np.uint8)  # Resize to 84x84\n",
        "            state_buffer.append(next_state)\n",
        "            done = done or truncated\n",
        "            memory.push(stacked_state, action, reward, np.stack(state_buffer, axis=0), done)\n",
        "            total_reward += reward\n",
        "            steps_done += 1\n",
        "            step += 1\n",
        "\n",
        "            if len(memory) > batch_size:\n",
        "                transitions = memory.sample(batch_size)\n",
        "                batch_state, batch_action, batch_reward, batch_next_state, batch_done = zip(*transitions)\n",
        "\n",
        "                batch_state = torch.tensor(np.array(batch_state), dtype=torch.float32) / 255.0\n",
        "                batch_action = torch.tensor(batch_action, dtype=torch.int64).unsqueeze(1)\n",
        "                batch_reward = torch.tensor(batch_reward, dtype=torch.float32).unsqueeze(1)\n",
        "                batch_next_state = torch.tensor(np.array(batch_next_state), dtype=torch.float32) / 255.0\n",
        "                batch_done = torch.tensor(batch_done, dtype=torch.float32).unsqueeze(1)\n",
        "\n",
        "                current_q_values = policy_net(batch_state).gather(1, batch_action)\n",
        "                next_q_values = target_net(batch_next_state).max(1)[0].detach().unsqueeze(1)\n",
        "                expected_q_values = batch_reward + (gamma * next_q_values * (1 - batch_done))\n",
        "\n",
        "                loss = nn.MSELoss()(current_q_values, expected_q_values)\n",
        "                optimizer.zero_grad()\n",
        "                loss.backward()\n",
        "                optimizer.step()\n",
        "\n",
        "        if episode % target_update == 0:\n",
        "            target_net.load_state_dict(policy_net.state_dict())\n",
        "\n",
        "        print(f\"Episode {episode}, Total Reward: {total_reward}\")\n",
        "\n",
        "    env.close()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ciwm9nCEzhr7"
      },
      "outputs": [],
      "source": [
        "def evaluate_agent(env, max_steps, n_eval_episodes, policy_net, epsilon=0):\n",
        "    episode_rewards = []\n",
        "\n",
        "    for episode in range(n_eval_episodes):\n",
        "        state, _ = env.reset()\n",
        "        state_buffer = deque(maxlen=4)\n",
        "        state = cv2.cvtColor(state, cv2.COLOR_RGB2GRAY)\n",
        "        state = cv2.resize(state, (84, 84))\n",
        "        state_buffer.extend([state] * 4)\n",
        "        total_reward = 0\n",
        "        done = False\n",
        "\n",
        "        for step in range(max_steps):\n",
        "            stacked_state = np.stack(state_buffer, axis=0)\n",
        "            action = epsilon_greedy_policy(stacked_state, epsilon, env.action_space.n, policy_net)\n",
        "            next_state, reward, done, truncated, _ = env.step(action)\n",
        "            next_state = cv2.cvtColor(next_state, cv2.COLOR_RGB2GRAY)\n",
        "            next_state = cv2.resize(next_state, (84, 84))\n",
        "            state_buffer.append(next_state)\n",
        "            total_reward += reward\n",
        "\n",
        "            if done or truncated:\n",
        "                break\n",
        "\n",
        "        episode_rewards.append(total_reward)\n",
        "\n",
        "    mean_reward = np.mean(episode_rewards)\n",
        "    std_reward = np.std(episode_rewards)\n",
        "    return mean_reward, std_reward"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4sH6PWllzlPh"
      },
      "outputs": [],
      "source": [
        "def record_video(env, policy_net, out_directory, fps=30):\n",
        "    images = []\n",
        "    state, _ = env.reset()\n",
        "    state_buffer = deque(maxlen=4)\n",
        "    state = cv2.cvtColor(state, cv2.COLOR_RGB2GRAY)\n",
        "    state = cv2.resize(state, (84, 84))\n",
        "    state_buffer.extend([state] * 4)\n",
        "    done = False\n",
        "\n",
        "    while not done:\n",
        "        img = env.render()\n",
        "        images.append(img)\n",
        "        stacked_state = np.stack(state_buffer, axis=0)\n",
        "        action = epsilon_greedy_policy(stacked_state, 0, env.action_space.n, policy_net)\n",
        "        next_state, reward, done, truncated, _ = env.step(action)\n",
        "        next_state = cv2.cvtColor(next_state, cv2.COLOR_RGB2GRAY)\n",
        "        next_state = cv2.resize(next_state, (84, 84))\n",
        "        state_buffer.append(next_state)\n",
        "        done = done or truncated\n",
        "\n",
        "    imageio.mimsave(out_directory, [np.array(img) for img in images], fps=fps)\n",
        "    print(f\"Video saved at {out_directory}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YHofNWj5zp3F"
      },
      "outputs": [],
      "source": [
        "# Function to display video\n",
        "def show_video(video_path, video_width=500):\n",
        "    video_file = open(video_path, \"r+b\").read()\n",
        "    video_url = f\"data:video/mp4;base64,{b64encode(video_file).decode()}\"\n",
        "    return HTML(f\"\"\"<video width={video_width} controls><source src=\"{video_url}\"></video>\"\"\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "V40bjY-lzs8f",
        "outputId": "a6f63780-8c2a-4236-bc8f-6731716e0f7f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Episode 0, Total Reward: 176.0\n",
            "Episode 1, Total Reward: 352.0\n",
            "Episode 2, Total Reward: 396.0\n",
            "Episode 3, Total Reward: 264.0\n",
            "Episode 4, Total Reward: 440.0\n",
            "Episode 5, Total Reward: 220.0\n",
            "Episode 6, Total Reward: 308.0\n",
            "Episode 7, Total Reward: 352.0\n",
            "Episode 8, Total Reward: 132.0\n",
            "Episode 9, Total Reward: 352.0\n",
            "Episode 10, Total Reward: 264.0\n",
            "Episode 11, Total Reward: 440.0\n",
            "Episode 12, Total Reward: 264.0\n",
            "Episode 13, Total Reward: 352.0\n",
            "Episode 14, Total Reward: 132.0\n",
            "Episode 15, Total Reward: 176.0\n",
            "Episode 16, Total Reward: 88.0\n",
            "Episode 17, Total Reward: 264.0\n",
            "Episode 18, Total Reward: 264.0\n",
            "Episode 19, Total Reward: 88.0\n",
            "Episode 20, Total Reward: 176.0\n",
            "Episode 21, Total Reward: 220.0\n",
            "Episode 22, Total Reward: 264.0\n",
            "Episode 23, Total Reward: 264.0\n",
            "Episode 24, Total Reward: 440.0\n",
            "Episode 25, Total Reward: 176.0\n",
            "Episode 26, Total Reward: 528.0\n",
            "Episode 27, Total Reward: 308.0\n",
            "Episode 28, Total Reward: 264.0\n",
            "Episode 29, Total Reward: 440.0\n",
            "Episode 30, Total Reward: 220.0\n",
            "Episode 31, Total Reward: 308.0\n",
            "Episode 32, Total Reward: 220.0\n",
            "Episode 33, Total Reward: 88.0\n",
            "Episode 34, Total Reward: 308.0\n",
            "Episode 35, Total Reward: 264.0\n",
            "Episode 36, Total Reward: 352.0\n",
            "Episode 37, Total Reward: 308.0\n",
            "Episode 38, Total Reward: 264.0\n",
            "Episode 39, Total Reward: 396.0\n",
            "Episode 40, Total Reward: 308.0\n",
            "Episode 41, Total Reward: 352.0\n",
            "Episode 42, Total Reward: 264.0\n",
            "Episode 43, Total Reward: 352.0\n",
            "Episode 44, Total Reward: 220.0\n",
            "Episode 45, Total Reward: 308.0\n",
            "Episode 46, Total Reward: 220.0\n",
            "Episode 47, Total Reward: 264.0\n",
            "Episode 48, Total Reward: 396.0\n",
            "Episode 49, Total Reward: 220.0\n",
            "Episode 50, Total Reward: 396.0\n",
            "Episode 51, Total Reward: 176.0\n",
            "Episode 52, Total Reward: 396.0\n",
            "Episode 53, Total Reward: 264.0\n",
            "Episode 54, Total Reward: 308.0\n",
            "Episode 55, Total Reward: 352.0\n",
            "Episode 56, Total Reward: 220.0\n",
            "Episode 57, Total Reward: 352.0\n",
            "Episode 58, Total Reward: 352.0\n",
            "Episode 59, Total Reward: 176.0\n",
            "Episode 60, Total Reward: 352.0\n",
            "Episode 61, Total Reward: 264.0\n",
            "Episode 62, Total Reward: 88.0\n",
            "Episode 63, Total Reward: 264.0\n",
            "Episode 64, Total Reward: 264.0\n",
            "Episode 65, Total Reward: 264.0\n",
            "Episode 66, Total Reward: 264.0\n",
            "Episode 67, Total Reward: 352.0\n",
            "Episode 68, Total Reward: 176.0\n",
            "Episode 69, Total Reward: 308.0\n",
            "Episode 70, Total Reward: 308.0\n",
            "Episode 71, Total Reward: 352.0\n",
            "Episode 72, Total Reward: 308.0\n",
            "Episode 73, Total Reward: 264.0\n",
            "Episode 74, Total Reward: 88.0\n",
            "Episode 75, Total Reward: 352.0\n",
            "Episode 76, Total Reward: 264.0\n",
            "Episode 77, Total Reward: 352.0\n",
            "Episode 78, Total Reward: 528.0\n",
            "Episode 79, Total Reward: 308.0\n",
            "Episode 80, Total Reward: 132.0\n",
            "Episode 81, Total Reward: 308.0\n",
            "Episode 82, Total Reward: 352.0\n",
            "Episode 83, Total Reward: 264.0\n",
            "Episode 84, Total Reward: 132.0\n",
            "Episode 85, Total Reward: 264.0\n",
            "Episode 86, Total Reward: 264.0\n",
            "Episode 87, Total Reward: 396.0\n",
            "Episode 88, Total Reward: 220.0\n",
            "Episode 89, Total Reward: 264.0\n",
            "Episode 90, Total Reward: 264.0\n",
            "Episode 91, Total Reward: 88.0\n",
            "Episode 92, Total Reward: 396.0\n",
            "Episode 93, Total Reward: 396.0\n",
            "Episode 94, Total Reward: 176.0\n",
            "Episode 95, Total Reward: 352.0\n",
            "Episode 96, Total Reward: 264.0\n",
            "Episode 97, Total Reward: 220.0\n",
            "Episode 98, Total Reward: 220.0\n",
            "Episode 99, Total Reward: 352.0\n",
            "Episode 100, Total Reward: 308.0\n",
            "Episode 101, Total Reward: 264.0\n",
            "Episode 102, Total Reward: 308.0\n",
            "Episode 103, Total Reward: 220.0\n",
            "Episode 104, Total Reward: 220.0\n",
            "Episode 105, Total Reward: 176.0\n",
            "Episode 106, Total Reward: 308.0\n",
            "Episode 107, Total Reward: 264.0\n",
            "Episode 108, Total Reward: 264.0\n",
            "Episode 109, Total Reward: 484.0\n",
            "Episode 110, Total Reward: 264.0\n",
            "Episode 111, Total Reward: 264.0\n",
            "Episode 112, Total Reward: 264.0\n",
            "Episode 113, Total Reward: 352.0\n",
            "Episode 114, Total Reward: 220.0\n",
            "Episode 115, Total Reward: 264.0\n",
            "Episode 116, Total Reward: 264.0\n",
            "Episode 117, Total Reward: 220.0\n",
            "Episode 118, Total Reward: 308.0\n",
            "Episode 119, Total Reward: 264.0\n",
            "Episode 120, Total Reward: 264.0\n",
            "Episode 121, Total Reward: 264.0\n",
            "Episode 122, Total Reward: 220.0\n",
            "Episode 123, Total Reward: 264.0\n",
            "Episode 124, Total Reward: 132.0\n",
            "Episode 125, Total Reward: 308.0\n",
            "Episode 126, Total Reward: 396.0\n",
            "Episode 127, Total Reward: 308.0\n",
            "Episode 128, Total Reward: 308.0\n",
            "Episode 129, Total Reward: 352.0\n",
            "Episode 130, Total Reward: 264.0\n",
            "Episode 131, Total Reward: 264.0\n",
            "Episode 132, Total Reward: 352.0\n",
            "Episode 133, Total Reward: 572.0\n",
            "Episode 134, Total Reward: 308.0\n",
            "Episode 135, Total Reward: 176.0\n",
            "Episode 136, Total Reward: 308.0\n",
            "Episode 137, Total Reward: 264.0\n",
            "Episode 138, Total Reward: 88.0\n",
            "Episode 139, Total Reward: 352.0\n",
            "Episode 140, Total Reward: 132.0\n",
            "Episode 141, Total Reward: 440.0\n",
            "Episode 142, Total Reward: 176.0\n",
            "Episode 143, Total Reward: 176.0\n",
            "Episode 144, Total Reward: 308.0\n",
            "Episode 145, Total Reward: 352.0\n",
            "Episode 146, Total Reward: 308.0\n",
            "Episode 147, Total Reward: 308.0\n",
            "Episode 148, Total Reward: 132.0\n",
            "Episode 149, Total Reward: 264.0\n",
            "Episode 150, Total Reward: 220.0\n",
            "Episode 151, Total Reward: 132.0\n",
            "Episode 152, Total Reward: 440.0\n",
            "Episode 153, Total Reward: 352.0\n",
            "Episode 154, Total Reward: 220.0\n",
            "Episode 155, Total Reward: 176.0\n",
            "Episode 156, Total Reward: 440.0\n",
            "Episode 157, Total Reward: 132.0\n",
            "Episode 158, Total Reward: 396.0\n",
            "Episode 159, Total Reward: 264.0\n",
            "Episode 160, Total Reward: 176.0\n",
            "Episode 161, Total Reward: 132.0\n",
            "Episode 162, Total Reward: 176.0\n",
            "Episode 163, Total Reward: 176.0\n",
            "Episode 164, Total Reward: 264.0\n",
            "Episode 165, Total Reward: 264.0\n",
            "Episode 166, Total Reward: 176.0\n",
            "Episode 167, Total Reward: 176.0\n",
            "Episode 168, Total Reward: 220.0\n",
            "Episode 169, Total Reward: 220.0\n",
            "Episode 170, Total Reward: 352.0\n",
            "Episode 171, Total Reward: 220.0\n",
            "Episode 172, Total Reward: 220.0\n",
            "Episode 173, Total Reward: 352.0\n",
            "Episode 174, Total Reward: 264.0\n",
            "Episode 175, Total Reward: 352.0\n",
            "Episode 176, Total Reward: 132.0\n",
            "Episode 177, Total Reward: 220.0\n",
            "Episode 178, Total Reward: 220.0\n",
            "Episode 179, Total Reward: 264.0\n",
            "Episode 180, Total Reward: 88.0\n",
            "Episode 181, Total Reward: 308.0\n",
            "Episode 182, Total Reward: 176.0\n",
            "Episode 183, Total Reward: 132.0\n",
            "Episode 184, Total Reward: 440.0\n",
            "Episode 185, Total Reward: 264.0\n",
            "Episode 186, Total Reward: 264.0\n",
            "Episode 187, Total Reward: 220.0\n",
            "Episode 188, Total Reward: 264.0\n",
            "Episode 189, Total Reward: 176.0\n",
            "Episode 190, Total Reward: 308.0\n",
            "Episode 191, Total Reward: 220.0\n",
            "Episode 192, Total Reward: 220.0\n",
            "Episode 193, Total Reward: 176.0\n",
            "Episode 194, Total Reward: 396.0\n",
            "Episode 195, Total Reward: 220.0\n",
            "Episode 196, Total Reward: 176.0\n",
            "Episode 197, Total Reward: 352.0\n",
            "Episode 198, Total Reward: 308.0\n",
            "Episode 199, Total Reward: 264.0\n",
            "Episode 200, Total Reward: 396.0\n",
            "Episode 201, Total Reward: 308.0\n",
            "Episode 202, Total Reward: 176.0\n",
            "Episode 203, Total Reward: 308.0\n",
            "Episode 204, Total Reward: 220.0\n",
            "Episode 205, Total Reward: 88.0\n",
            "Episode 206, Total Reward: 264.0\n",
            "Episode 207, Total Reward: 132.0\n",
            "Episode 208, Total Reward: 220.0\n",
            "Episode 209, Total Reward: 220.0\n",
            "Episode 210, Total Reward: 176.0\n",
            "Episode 211, Total Reward: 352.0\n",
            "Episode 212, Total Reward: 176.0\n",
            "Episode 213, Total Reward: 88.0\n",
            "Episode 214, Total Reward: 396.0\n",
            "Episode 215, Total Reward: 220.0\n",
            "Episode 216, Total Reward: 352.0\n",
            "Episode 217, Total Reward: 396.0\n",
            "Episode 218, Total Reward: 220.0\n",
            "Episode 219, Total Reward: 308.0\n",
            "Episode 220, Total Reward: 352.0\n",
            "Episode 221, Total Reward: 220.0\n",
            "Episode 222, Total Reward: 176.0\n",
            "Episode 223, Total Reward: 176.0\n",
            "Episode 224, Total Reward: 176.0\n",
            "Episode 225, Total Reward: 440.0\n",
            "Episode 226, Total Reward: 352.0\n",
            "Episode 227, Total Reward: 176.0\n",
            "Episode 228, Total Reward: 88.0\n",
            "Episode 229, Total Reward: 264.0\n",
            "Episode 230, Total Reward: 176.0\n",
            "Episode 231, Total Reward: 88.0\n",
            "Episode 232, Total Reward: 88.0\n",
            "Episode 233, Total Reward: 176.0\n",
            "Episode 234, Total Reward: 132.0\n",
            "Episode 235, Total Reward: 132.0\n",
            "Episode 236, Total Reward: 352.0\n",
            "Episode 237, Total Reward: 176.0\n",
            "Episode 238, Total Reward: 220.0\n",
            "Episode 239, Total Reward: 220.0\n",
            "Episode 240, Total Reward: 220.0\n",
            "Episode 241, Total Reward: 220.0\n",
            "Episode 242, Total Reward: 220.0\n",
            "Episode 243, Total Reward: 132.0\n",
            "Episode 244, Total Reward: 220.0\n",
            "Episode 245, Total Reward: 176.0\n",
            "Episode 246, Total Reward: 264.0\n",
            "Episode 247, Total Reward: 352.0\n",
            "Episode 248, Total Reward: 308.0\n",
            "Episode 249, Total Reward: 352.0\n",
            "Episode 250, Total Reward: 220.0\n",
            "Episode 251, Total Reward: 264.0\n",
            "Episode 252, Total Reward: 352.0\n",
            "Episode 253, Total Reward: 440.0\n",
            "Episode 254, Total Reward: 176.0\n",
            "Episode 255, Total Reward: 220.0\n",
            "Episode 256, Total Reward: 572.0\n",
            "Episode 257, Total Reward: 352.0\n",
            "Episode 258, Total Reward: 396.0\n",
            "Episode 259, Total Reward: 352.0\n",
            "Episode 260, Total Reward: 352.0\n",
            "Episode 261, Total Reward: 176.0\n",
            "Episode 262, Total Reward: 308.0\n",
            "Episode 263, Total Reward: 352.0\n",
            "Episode 264, Total Reward: 440.0\n",
            "Episode 265, Total Reward: 176.0\n",
            "Episode 266, Total Reward: 352.0\n",
            "Episode 267, Total Reward: 264.0\n",
            "Episode 268, Total Reward: 176.0\n",
            "Episode 269, Total Reward: 264.0\n",
            "Episode 270, Total Reward: 396.0\n",
            "Episode 271, Total Reward: 264.0\n",
            "Episode 272, Total Reward: 88.0\n",
            "Episode 273, Total Reward: 528.0\n",
            "Episode 274, Total Reward: 132.0\n",
            "Episode 275, Total Reward: 308.0\n",
            "Episode 276, Total Reward: 264.0\n",
            "Episode 277, Total Reward: 220.0\n",
            "Episode 278, Total Reward: 176.0\n",
            "Episode 279, Total Reward: 176.0\n",
            "Episode 280, Total Reward: 132.0\n",
            "Episode 281, Total Reward: 176.0\n",
            "Episode 282, Total Reward: 220.0\n",
            "Episode 283, Total Reward: 308.0\n",
            "Episode 284, Total Reward: 88.0\n",
            "Episode 285, Total Reward: 176.0\n",
            "Episode 286, Total Reward: 220.0\n",
            "Episode 287, Total Reward: 264.0\n",
            "Episode 288, Total Reward: 220.0\n",
            "Episode 289, Total Reward: 176.0\n",
            "Episode 290, Total Reward: 132.0\n",
            "Episode 291, Total Reward: 88.0\n",
            "Episode 292, Total Reward: 132.0\n",
            "Episode 293, Total Reward: 176.0\n",
            "Episode 294, Total Reward: 88.0\n",
            "Episode 295, Total Reward: 176.0\n",
            "Episode 296, Total Reward: 132.0\n",
            "Episode 297, Total Reward: 264.0\n",
            "Episode 298, Total Reward: 44.0\n",
            "Episode 299, Total Reward: 44.0\n",
            "Episode 300, Total Reward: 220.0\n",
            "Episode 301, Total Reward: 132.0\n",
            "Episode 302, Total Reward: 264.0\n",
            "Episode 303, Total Reward: 308.0\n",
            "Episode 304, Total Reward: 176.0\n",
            "Episode 305, Total Reward: 220.0\n",
            "Episode 306, Total Reward: 176.0\n",
            "Episode 307, Total Reward: 264.0\n",
            "Episode 308, Total Reward: 220.0\n",
            "Episode 309, Total Reward: 132.0\n",
            "Episode 310, Total Reward: 220.0\n",
            "Episode 311, Total Reward: 176.0\n",
            "Episode 312, Total Reward: 176.0\n",
            "Episode 313, Total Reward: 176.0\n",
            "Episode 314, Total Reward: 176.0\n",
            "Episode 315, Total Reward: 88.0\n",
            "Episode 316, Total Reward: 264.0\n",
            "Episode 317, Total Reward: 264.0\n",
            "Episode 318, Total Reward: 132.0\n",
            "Episode 319, Total Reward: 88.0\n",
            "Episode 320, Total Reward: 44.0\n",
            "Episode 321, Total Reward: 220.0\n",
            "Episode 322, Total Reward: 88.0\n",
            "Episode 323, Total Reward: 88.0\n",
            "Episode 324, Total Reward: 176.0\n",
            "Episode 325, Total Reward: 352.0\n",
            "Episode 326, Total Reward: 88.0\n",
            "Episode 327, Total Reward: 132.0\n",
            "Episode 328, Total Reward: 352.0\n",
            "Episode 329, Total Reward: 352.0\n",
            "Episode 330, Total Reward: 176.0\n",
            "Episode 331, Total Reward: 264.0\n",
            "Episode 332, Total Reward: 176.0\n",
            "Episode 333, Total Reward: 132.0\n",
            "Episode 334, Total Reward: 88.0\n",
            "Episode 335, Total Reward: 176.0\n",
            "Episode 336, Total Reward: 220.0\n",
            "Episode 337, Total Reward: 132.0\n",
            "Episode 338, Total Reward: 264.0\n",
            "Episode 339, Total Reward: 396.0\n",
            "Episode 340, Total Reward: 396.0\n",
            "Episode 341, Total Reward: 264.0\n",
            "Episode 342, Total Reward: 176.0\n",
            "Episode 343, Total Reward: 176.0\n",
            "Episode 344, Total Reward: 220.0\n",
            "Episode 345, Total Reward: 176.0\n",
            "Episode 346, Total Reward: 88.0\n",
            "Episode 347, Total Reward: 484.0\n",
            "Episode 348, Total Reward: 220.0\n",
            "Episode 349, Total Reward: 44.0\n",
            "Episode 350, Total Reward: 88.0\n",
            "Episode 351, Total Reward: 220.0\n",
            "Episode 352, Total Reward: 88.0\n",
            "Episode 353, Total Reward: 88.0\n",
            "Episode 354, Total Reward: 132.0\n",
            "Episode 355, Total Reward: 132.0\n",
            "Episode 356, Total Reward: 132.0\n",
            "Episode 357, Total Reward: 396.0\n",
            "Episode 358, Total Reward: 176.0\n",
            "Episode 359, Total Reward: 176.0\n",
            "Episode 360, Total Reward: 220.0\n",
            "Episode 361, Total Reward: 220.0\n",
            "Episode 362, Total Reward: 176.0\n",
            "Episode 363, Total Reward: 264.0\n",
            "Episode 364, Total Reward: 220.0\n",
            "Episode 365, Total Reward: 176.0\n",
            "Episode 366, Total Reward: 176.0\n",
            "Episode 367, Total Reward: 44.0\n",
            "Episode 368, Total Reward: 176.0\n",
            "Episode 369, Total Reward: 220.0\n",
            "Episode 370, Total Reward: 396.0\n",
            "Episode 371, Total Reward: 88.0\n",
            "Episode 372, Total Reward: 132.0\n",
            "Episode 373, Total Reward: 308.0\n",
            "Episode 374, Total Reward: 176.0\n",
            "Episode 375, Total Reward: 220.0\n",
            "Episode 376, Total Reward: 220.0\n",
            "Episode 377, Total Reward: 264.0\n",
            "Episode 378, Total Reward: 88.0\n",
            "Episode 379, Total Reward: 220.0\n",
            "Episode 380, Total Reward: 88.0\n",
            "Episode 381, Total Reward: 88.0\n",
            "Episode 382, Total Reward: 88.0\n",
            "Episode 383, Total Reward: 176.0\n",
            "Episode 384, Total Reward: 220.0\n",
            "Episode 385, Total Reward: 264.0\n",
            "Episode 386, Total Reward: 132.0\n",
            "Episode 387, Total Reward: 264.0\n",
            "Episode 388, Total Reward: 264.0\n",
            "Episode 389, Total Reward: 308.0\n",
            "Episode 390, Total Reward: 176.0\n",
            "Episode 391, Total Reward: 88.0\n",
            "Episode 392, Total Reward: 88.0\n",
            "Episode 393, Total Reward: 220.0\n",
            "Episode 394, Total Reward: 220.0\n",
            "Episode 395, Total Reward: 308.0\n",
            "Episode 396, Total Reward: 176.0\n",
            "Episode 397, Total Reward: 308.0\n",
            "Episode 398, Total Reward: 220.0\n",
            "Episode 399, Total Reward: 176.0\n",
            "Episode 400, Total Reward: 132.0\n",
            "Episode 401, Total Reward: 396.0\n",
            "Episode 402, Total Reward: 264.0\n",
            "Episode 403, Total Reward: 308.0\n",
            "Episode 404, Total Reward: 88.0\n",
            "Episode 405, Total Reward: 264.0\n",
            "Episode 406, Total Reward: 132.0\n",
            "Episode 407, Total Reward: 88.0\n",
            "Episode 408, Total Reward: 88.0\n",
            "Episode 409, Total Reward: 176.0\n",
            "Episode 410, Total Reward: 88.0\n",
            "Episode 411, Total Reward: 176.0\n",
            "Episode 412, Total Reward: 176.0\n",
            "Episode 413, Total Reward: 220.0\n",
            "Episode 414, Total Reward: 88.0\n",
            "Episode 415, Total Reward: 220.0\n",
            "Episode 416, Total Reward: 220.0\n",
            "Episode 417, Total Reward: 308.0\n",
            "Episode 418, Total Reward: 88.0\n",
            "Episode 419, Total Reward: 220.0\n",
            "Episode 420, Total Reward: 352.0\n",
            "Episode 421, Total Reward: 88.0\n",
            "Episode 422, Total Reward: 176.0\n",
            "Episode 423, Total Reward: 308.0\n",
            "Episode 424, Total Reward: 176.0\n",
            "Episode 425, Total Reward: 132.0\n",
            "Episode 426, Total Reward: 176.0\n",
            "Episode 427, Total Reward: 176.0\n",
            "Episode 428, Total Reward: 308.0\n",
            "Episode 429, Total Reward: 88.0\n",
            "Episode 430, Total Reward: 176.0\n",
            "Episode 431, Total Reward: 0.0\n",
            "Episode 432, Total Reward: 132.0\n",
            "Episode 433, Total Reward: 132.0\n",
            "Episode 434, Total Reward: 88.0\n",
            "Episode 435, Total Reward: 132.0\n",
            "Episode 436, Total Reward: 176.0\n",
            "Episode 437, Total Reward: 220.0\n",
            "Episode 438, Total Reward: 264.0\n",
            "Episode 439, Total Reward: 176.0\n",
            "Episode 440, Total Reward: 352.0\n",
            "Episode 441, Total Reward: 44.0\n",
            "Episode 442, Total Reward: 44.0\n",
            "Episode 443, Total Reward: 88.0\n",
            "Episode 444, Total Reward: 0.0\n",
            "Episode 445, Total Reward: 88.0\n",
            "Episode 446, Total Reward: 132.0\n",
            "Episode 447, Total Reward: 132.0\n",
            "Episode 448, Total Reward: 176.0\n",
            "Episode 449, Total Reward: 264.0\n",
            "Episode 450, Total Reward: 0.0\n",
            "Episode 451, Total Reward: 132.0\n",
            "Episode 452, Total Reward: 220.0\n",
            "Episode 453, Total Reward: 88.0\n",
            "Episode 454, Total Reward: 0.0\n",
            "Episode 455, Total Reward: 176.0\n",
            "Episode 456, Total Reward: 220.0\n",
            "Episode 457, Total Reward: 88.0\n",
            "Episode 458, Total Reward: 88.0\n",
            "Episode 459, Total Reward: 88.0\n",
            "Episode 460, Total Reward: 264.0\n",
            "Episode 461, Total Reward: 264.0\n",
            "Episode 462, Total Reward: 220.0\n",
            "Episode 463, Total Reward: 88.0\n",
            "Episode 464, Total Reward: 176.0\n",
            "Episode 465, Total Reward: 88.0\n",
            "Episode 466, Total Reward: 132.0\n",
            "Episode 467, Total Reward: 176.0\n",
            "Episode 468, Total Reward: 88.0\n",
            "Episode 469, Total Reward: 44.0\n",
            "Episode 470, Total Reward: 132.0\n",
            "Episode 471, Total Reward: 88.0\n",
            "Episode 472, Total Reward: 132.0\n",
            "Episode 473, Total Reward: 44.0\n",
            "Episode 474, Total Reward: 132.0\n",
            "Episode 475, Total Reward: 220.0\n",
            "Episode 476, Total Reward: 88.0\n",
            "Episode 477, Total Reward: 176.0\n",
            "Episode 478, Total Reward: 220.0\n",
            "Episode 479, Total Reward: 88.0\n",
            "Episode 480, Total Reward: 220.0\n",
            "Episode 481, Total Reward: 44.0\n",
            "Episode 482, Total Reward: 176.0\n",
            "Episode 483, Total Reward: 88.0\n",
            "Episode 484, Total Reward: 44.0\n",
            "Episode 485, Total Reward: 220.0\n",
            "Episode 486, Total Reward: 176.0\n",
            "Episode 487, Total Reward: 88.0\n",
            "Episode 488, Total Reward: 220.0\n",
            "Episode 489, Total Reward: 220.0\n",
            "Episode 490, Total Reward: 264.0\n",
            "Episode 491, Total Reward: 132.0\n",
            "Episode 492, Total Reward: 44.0\n",
            "Episode 493, Total Reward: 44.0\n",
            "Episode 494, Total Reward: 132.0\n",
            "Episode 495, Total Reward: 132.0\n",
            "Episode 496, Total Reward: 132.0\n",
            "Episode 497, Total Reward: 264.0\n",
            "Episode 498, Total Reward: 308.0\n",
            "Episode 499, Total Reward: 88.0\n",
            "Evaluation - Mean Reward: 391.6, Std Reward: 23.69472515139182\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:imageio_ffmpeg:IMAGEIO FFMPEG_WRITER WARNING: input image is not divisible by macro_block_size=16, resizing from (160, 210) to (160, 224) to ensure video compatibility with most codecs and players. To prevent resizing, make your input image divisible by the macro_block_size or set the macro_block_size to 1 (risking incompatibility).\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Video saved at Agent.mp4\n"
          ]
        }
      ],
      "source": [
        "if __name__ == \"__main__\":\n",
        "    train_dqn()\n",
        "    env = gym.make(env_name, render_mode='rgb_array')\n",
        "    mean_reward, std_reward = evaluate_agent(env, max_steps=1000, n_eval_episodes=10, policy_net=DQN((4, 84, 84), env.action_space.n))\n",
        "    print(f\"Evaluation - Mean Reward: {mean_reward}, Std Reward: {std_reward}\")\n",
        "    record_video(env, DQN((4, 84, 84), env.action_space.n), \"Agent.mp4\")\n",
        "    show_video(\"Agent.mp4\")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "A100",
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
